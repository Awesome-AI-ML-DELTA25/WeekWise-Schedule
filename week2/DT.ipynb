{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7f9aaa",
   "metadata": {},
   "source": [
    "# Decision Trees model\n",
    "\n",
    "Decision trees are a type of supervised learning algorithm that can be used for both classification and regression tasks. They work by splitting the data into subsets based on the value of input features, creating a tree-like structure where each node represents a feature and each branch represents a decision based on that feature. The final output is a leaf node that represents the predicted class or value. Decision trees are easy to interpret and visualize, making them a popular choice for many machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ca68f",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82480611",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'cleaned_titanic_dataset.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92393849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature and target variables\n",
    "y = df['survived']\n",
    "X = df.drop('survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical and numerical columns\n",
    "categorical_cols = ['pclass', 'sex', 'embarked']\n",
    "numeric_cols = [col for col in X.columns if col not in categorical_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8674df",
   "metadata": {},
   "source": [
    "## Numbers are better than words\n",
    "\n",
    "Decision trees have no way to understand words, so we need to convert them into numbers. We use OneHotEncoding to convert categorical variables into a format that can be provided to ML algorithms to do a better job in prediction.\n",
    "\n",
    "OneHotEncoding creates a new binary column for each category in the original column. For example, if we have a column \"Color\" with three categories: \"Red\", \"Green\", and \"Blue\", OneHotEncoding will create three new columns: \"Color_Red\", \"Color_Green\", and \"Color_Blue\". Each row will have a value of 1 in the column corresponding to its original category and 0 in the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f47578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with preprocessing and classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42, max_depth=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44827733",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "## Some terms\n",
    "- **True Positive (TP)**: The model correctly predicted the positive class.\n",
    "- **True Negative (TN)**: The model correctly predicted the negative class.\n",
    "- **False Positive (FP)**: The model incorrectly predicted the positive class (Type I error).\n",
    "- **False Negative (FN)**: The model incorrectly predicted the negative class (Type II error).\n",
    "\n",
    "## Some metrics\n",
    "### Confusion Matrix\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "TP & FN \\\\\n",
    "FP & TN\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "### Accuracy\n",
    "$$\n",
    "Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "### Precision\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "### Recall\n",
    "$$\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "### F1 Score\n",
    "$$\n",
    "F1 Score = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341a2cf",
   "metadata": {},
   "source": [
    "# More Metrics\n",
    "## Mean Squared Error (MSE)\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "Where:\n",
    "- \\( n \\) is the number of samples\n",
    "- \\( y_i \\) is the true value\n",
    "- \\( \\hat{y}_i \\) is the predicted value\n",
    "\n",
    "## Mean Absolute Error (MAE)\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "Where:\n",
    "- \\( n \\) is the number of samples\n",
    "- \\( y_i \\) is the true value\n",
    "- \\( \\hat{y}_i \\) is the predicted value\n",
    "\n",
    "## R-squared\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
    "$$\n",
    "Where:\n",
    "- \\( n \\) is the number of samples\n",
    "- \\( y_i \\) is the true value\n",
    "- \\( \\hat{y}_i \\) is the predicted value\n",
    "- \\( \\bar{y} \\) is the mean of the true values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Survived', 'Survived'], yticklabels=['Not Survived', 'Survived'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2432b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.named_steps['classifier'].feature_importances_\n",
    "feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "plt.xticks(range(len(importances)), feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, len(importances)])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb03250",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(model.named_steps['classifier'], feature_names=feature_names, filled=True, rounded=True)\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'titanic_model_DT.pkl')\n",
    "# Load the model\n",
    "loaded_model = joblib.load('titanic_model_DT.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtxgb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
