{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7f9aaa",
   "metadata": {},
   "source": [
    "# XGBoost model\n",
    "Boosting is an ensemble learning technique that combines multiple weak learners to create a strong learner. It works by training a series of models sequentially, where each model tries to correct the errors made by the previous model. The final output is a weighted sum of the predictions from all the models. Boosting can be used with various types of base learners, but decision trees are commonly used due to their flexibility and interpretability.\n",
    "XGBoost (Extreme Gradient Boosting) is an optimized implementation of the gradient boosting algorithm that is designed to be highly efficient and scalable. It includes several advanced features such as regularization, parallel processing, and tree pruning, which help to improve the performance and reduce overfitting. XGBoost has become one of the most popular machine learning algorithms due to its speed and accuracy, especially in Kaggle competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier, plot_tree\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ca68f",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82480611",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'cleaned_titanic_dataset.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92393849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature and target variables\n",
    "y = df['survived']\n",
    "X = df.drop('survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical and numerical columns\n",
    "categorical_cols = ['pclass', 'sex', 'embarked']\n",
    "numeric_cols = [col for col in X.columns if col not in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f47578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with preprocessing and classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(eval_metric='logloss', max_depth=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Survived', 'Survived'], yticklabels=['Not Survived', 'Survived'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2432b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.named_steps['classifier'].feature_importances_\n",
    "feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "plt.xticks(range(len(importances)), feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, len(importances)])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb03250",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(model.named_steps['classifier'], tree_idx=0, rankdir='LR')\n",
    "plt.title('XGBoost Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'titanic_model_XGB.pkl')\n",
    "# Load the model\n",
    "loaded_model = joblib.load('titanic_model_XGB.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtxgb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
