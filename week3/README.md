# Week 3 Content
## Perceptrons and Multi-Layer Perceptrons
We begin out study of neural networks with the simplest form, the perceptron. A perceptron is a single-layer neural network that can be used for binary classification tasks. It consists of input features, weights, a bias term, and an activation function.

Moreover, perceptrons can be stacked to form multi-layer perceptrons (MLPs), which are capable of learning more complex functions. MLPs consist of multiple layers of neurons, where each layer applies a linear transformation followed by a non-linear activation function.

## Neural Networks using PyTorch
Neural networks is another name for MLPs. PyTorch provides a flexible framework for building and training neural networks. We explore how to implement MLPs using PyTorch, including defining the architecture, specifying the loss function, and training the model.